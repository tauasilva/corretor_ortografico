{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Corretor Ortográfico"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "import nltk\r\n",
    "nltk.download('punkt')\r\n",
    "\r\n",
    "with open(\"artigos.txt\", encoding=\"utf8\") as f:\r\n",
    "    artigos = f.read()\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\taua.fagundes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "def separa_palavras(lista_tokens):\r\n",
    "    lista_palavras = []\r\n",
    "    for token in lista_tokens:\r\n",
    "        if token.isalpha():\r\n",
    "            lista_palavras.append(token)\r\n",
    "    \r\n",
    "    return lista_palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\r\n",
    "\r\n",
    "palavras_separadas = separa_palavras(lista_tokens)\r\n",
    "\r\n",
    "len(palavras_separadas)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "403104"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "def normalizacao(lista_de_palavras):\r\n",
    "    lista_normalizada = []\r\n",
    "    for palavra in lista_de_palavras:\r\n",
    "        lista_normalizada.append(palavra.lower())\r\n",
    "    \r\n",
    "    return lista_normalizada\r\n",
    "\r\n",
    "lista_normalizada = normalizacao(palavras_separadas)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "def insere_caracter(fatias):\r\n",
    "    novas_palavras = []\r\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\r\n",
    "\r\n",
    "    for E,D in fatias:\r\n",
    "        for letra in letras:\r\n",
    "            novas_palavras.append(E + letra + D)\r\n",
    "\r\n",
    "    return novas_palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "def deletando_caracter(fatias):\r\n",
    "    \r\n",
    "    novas_palavras = []\r\n",
    "\r\n",
    "    for E,D in fatias:\r\n",
    "        novas_palavras.append(E + D[1:])\r\n",
    "\r\n",
    "    return novas_palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "def troca_caracter(fatias):\r\n",
    "    novas_palavras = []\r\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\r\n",
    "\r\n",
    "    for E,D in fatias:\r\n",
    "        for letra in letras:\r\n",
    "            novas_palavras.append(E + letra + D[1:])\r\n",
    "\r\n",
    "    return novas_palavras    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "def inverte_caracter(fatias):\r\n",
    "    novas_palavras = []\r\n",
    "\r\n",
    "    for E,D in fatias:\r\n",
    "        if(len(D) > 1):\r\n",
    "            novas_palavras.append(E + D[1] + D[0] +  D[2:])\r\n",
    "\r\n",
    "    return novas_palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "def gerador_palavras(palavra):\r\n",
    "\r\n",
    "    fatias = []\r\n",
    "\r\n",
    "\r\n",
    "    for i in range(len(palavra)+1):\r\n",
    "        fatias.append((palavra[:i],palavra[i:]))\r\n",
    "\r\n",
    "    palavras_geradas = insere_caracter(fatias)\r\n",
    "    palavras_geradas += deletando_caracter(fatias)\r\n",
    "    palavras_geradas += troca_caracter(fatias)\r\n",
    "    palavras_geradas += inverte_caracter(fatias)\r\n",
    "    \r\n",
    "    return palavras_geradas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "total_de_palavras = len(lista_normalizada)\r\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\r\n",
    "\r\n",
    "def probabilidade(palavra_gerada):\r\n",
    "    return frequencia[palavra_gerada]/total_de_palavras\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "def corretor(palavra: str):\r\n",
    "    '''\r\n",
    "        function Corretor ortográfico\r\n",
    "\r\n",
    "        palavra : palavra que vamos verificar \r\n",
    "    '''\r\n",
    "    palavras_geradas = gerador_palavras(palavra)\r\n",
    "\r\n",
    "    palavra_correta = max(palavras_geradas,key =probabilidade)\r\n",
    "\r\n",
    "    return palavra_correta\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testes e avaliação da performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "def cria_dados_de_testes(nome_do_arquivo):\r\n",
    "    list_de_palavras_teste = []\r\n",
    "\r\n",
    "    f = open(nome_do_arquivo, mode=\"r\", encoding=\"utf-8\")\r\n",
    "\r\n",
    "    for linha in f:\r\n",
    "        correta, errada = linha.split()\r\n",
    "        list_de_palavras_teste.append((correta,errada))\r\n",
    "\r\n",
    "    f.close()\r\n",
    "\r\n",
    "    return list_de_palavras_teste\r\n",
    "\r\n",
    "\r\n",
    "def avaliador(teste, vocabulario):\r\n",
    "    numero_de_palavras = len(teste)\r\n",
    "    acertou = 0\r\n",
    "    desconhecida = 0\r\n",
    "\r\n",
    "    for correta, errada in teste:\r\n",
    "        palavra_corrigida = corretor(errada)\r\n",
    "\r\n",
    "        desconhecida += (correta not in vocabulario)    \r\n",
    "        if palavra_corrigida == correta:\r\n",
    "            acertou +=1\r\n",
    "\r\n",
    "    taxa_acerto = acertou*100/numero_de_palavras\r\n",
    "    taxa_desconhecida = desconhecida*100/numero_de_palavras\r\n",
    "    print(f\"taxa de acerto {round(taxa_acerto,2)}% de {numero_de_palavras} palavras, desconhecidas é {taxa_desconhecida}%\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "lista_teste = cria_dados_de_testes('palavras.txt')\r\n",
    "\r\n",
    "vocabulario = set(lista_normalizada)\r\n",
    "avaliador(lista_teste,vocabulario)\r\n",
    "\r\n",
    "\r\n",
    "# v1.0 = taxa de acerto 0.1 % \r\n",
    "# v2.0 = taxa de acerto 41.4 % \r\n",
    "# v3.0 = taxa de acerto 76.34%\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "taxa de acerto 76.34% de 186 palavras, desconhecidas é 6.989247311827957%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "ea0dd97562e77bacfce6e2734ae2a4bd65e1c699c467f9e899bfa04a67c38880"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}